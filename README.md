# CNN-Cephalogram

## ğŸ‘¥ Authors

- **Tianyi** 
- **Quevin** 

---

## ğŸ“ Project Summary

**Landmark Annotation of Cephalograms using CNN**  
A deep learning-based solution for automated detection of anatomical landmarks in lateral cephalometric X-ray images. This tool streamlines the manual and error-prone process of identifying craniofacial reference points in dental imaging, leveraging the power of convolutional neural networks (CNNs).

---

## ğŸ“Œ Overview

This project presents a Convolutional Neural Network model trained to predict over 20 craniofacial landmarks from cephalometric radiographs. It is designed to assist dental professionals with high-precision, automated annotation of lateral skull X-rays.

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ Code/
â”‚   â”œâ”€â”€ chrome-win64/               # Automated downloading tool (Selenium-based)
â”‚   â”œâ”€â”€ Landmarks_CSV/              # Downloaded landmark CSVs
â”‚   â”œâ”€â”€ image/                      # Raw cephalogram images
â”‚   â”œâ”€â”€ processCSV/                 # Processed data outputs
â”‚   â”œâ”€â”€ best results code/         # Best training + model combo (final model)
â”‚   â”œâ”€â”€ images web crawler.py      # Downloads images
â”‚   â”œâ”€â”€ CSV web crawler.py         # Downloads landmark CSVs
â”‚   â”œâ”€â”€ annote auto.py             # Auto-annotates reference points (Sella/Nasion)
â”‚   â”œâ”€â”€ crop images.py             # Crops images to 800x800
â”‚   â”œâ”€â”€ data_process.py            # Preprocessing, filtering, coordinate transform
â”‚   â””â”€â”€ combine_data.py            # Combines datasets
â”‚
â”œâ”€â”€ code_evaluation/               # Model evaluation & SDR / MSE analysis
â”‚   â””â”€â”€ evaluation.py              # Run this to get SDR and MSE results
```

---

## âš™ï¸ How to Use

The code is divided into two parts:

1. **Main pipeline** (`Code/` folder):  
Includes downloading, preprocessing, CNN modeling, and training.  
   There are **three ways to run** the pipeline:
   - **Option 1**: Use the scripts in the `Code/` folder to download and process image data, and generate `Mathews_arrays.npz` and `checked_filename_case_mathews.npz`. Then, load them into `CNN_Modeling.ipynb` for training and prediction.
   - **Option 2**: Directly load our pre-processed files `Mathews_arrays.npz` and `checked_filename_case_mathews.npz` into `CNN_Modeling.ipynb` without rerunning the entire preprocessing pipeline.
   - **Option 3**: Use parts of `CNN_Modeling.ipynb` to load the pretrained model `best_model.h5` and make predictions. In this case, input images must be preprocessed to match the expected format used in our training pipeline.


2. **Evaluation script** (`code_evaluation/` folder):  
   After training is completed, use this part to evaluate model performance based on SDR and MSE.


## ğŸ§  CNN_Modeling.ipynb Instructions

`CNN_Modeling.ipynb` is responsible for:
- Final data preprocessing  
- Data augmentation (brightness & contrast changes)  
- CNN model construction, training, and prediction  
- Visualizing predicted landmark positions on the original cephalometric images

#### ğŸ“‚ Required Input Files

1. **`Mathews_arrays.npz`**  
   This file contains all processed image arrays and corresponding landmark labels.  
   ğŸ”— [Download here](https://drive.google.com/drive/folders/16q40trNkZ3DX2L2LBb_b3oT76YWiaALf?usp=drive_link)

2. **`checked_filename_case_mathews.npz`**  
   This file provides a list of filenames with verified landmark annotations.  
   ğŸ”— [Download here](https://drive.google.com/drive/folders/1P62Kaiw2NEr6_oJ3Wqhrt9xe8NW5hiR1?usp=drive_link)

3. **`best_model.h5`**  
   You can skip training and directly load the pre-trained model from this file.  
   ğŸ“ Available in the GitHub repository under `Code/`

#### ğŸ“¤ Output Files Generated

Running `CNN_Modeling.ipynb` will generate the following CSVs for downstream evaluation:

- `dataset_prediction_labels.csv` â€“ Predicted landmark coordinates  
- `dataset_ground_truth_labels.csv` â€“ Ground truth landmark coordinates  
- `dataset_filename.csv` â€“ Corresponding filenames for traceability

These files can be used as input for the accuracy evaluation script in the `code_evaluation/` folder.

---

ğŸ“ Data & Model Access
You can access all raw data, annotations, processed files, and model results from the following links:

ğŸ“· Original Cephalogram Images
ğŸ”— Google Drive â€“ Raw Images

ğŸ“ Original CSV Landmark Annotations
ğŸ”— Google Drive â€“ Raw CSV Files

ğŸ§  Final CNN Model Prediction Results (can be directly used for evaluation)
ğŸ”— Google Drive â€“ Prediction Output

âš™ï¸ All Preprocessed Image and Dataset Files (including arrays, filenames, cleaned data)
ğŸ”— Google Drive â€“ Preprocessed Dataset


